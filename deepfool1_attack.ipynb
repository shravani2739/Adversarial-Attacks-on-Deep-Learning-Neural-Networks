{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce57a6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b6ee745",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "131a74b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.data.iloc[idx, 1:].values.astype(np.uint8).reshape((28, 28))\n",
    "        label = self.data.iloc[idx, 0]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ea87ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import transforms\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "train_dataset = CustomDataset(csv_file='mnist_train.csv', transform=transform)\n",
    "test_dataset = CustomDataset(csv_file='mnist_test.csv', transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b48bf1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(4*4*64, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.max_pool2d(x, kernel_size=2)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.max_pool2d(x, kernel_size=2)\n",
    "        x = x.view(-1, 4*4*64)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = Net()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433f6c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model (optional)\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "# Uncomment to train the model\n",
    "train_model(model, train_loader, criterion, optimizer)\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'mnist_cnn.pth')\n",
    "\n",
    "# Load pre-trained model\n",
    "model.load_state_dict(torch.load('mnist_cnn.pth'))\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e81b06f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def deepfool_attack(image, model, num_classes=10, max_iter=100, epsilon=1e-3):\n",
    "    image = image.clone().detach().requires_grad_(True)\n",
    "    perturbed_image = image.clone()\n",
    "\n",
    "    # Forward pass to get the initial prediction\n",
    "    output = model(perturbed_image)\n",
    "    _, init_pred = torch.max(output, 1)\n",
    "    perturbed_image.requires_grad_(True)  # Ensure requires_grad is set to True\n",
    "\n",
    "    # Initialize perturbation and iteration counter\n",
    "    r_tot = torch.zeros_like(image)\n",
    "\n",
    "    for iter_count in range(max_iter):\n",
    "        # Calculate gradients\n",
    "        output = model(perturbed_image)\n",
    "        _, pred_label = torch.max(output, 1)\n",
    "        grad_orig = torch.autograd.grad(output[0, init_pred.item()], perturbed_image, create_graph=True)[0]\n",
    "\n",
    "        # Check if the prediction is different from initial prediction\n",
    "        if pred_label != init_pred.item():\n",
    "            break\n",
    "\n",
    "        # Calculate perturbation\n",
    "        min_perturbation = np.inf\n",
    "        for k in range(num_classes):\n",
    "            if k != init_pred.item():\n",
    "                grad_curr = torch.autograd.grad(output[0, k], perturbed_image, create_graph=True)[0]\n",
    "                w_k = grad_curr - grad_orig\n",
    "                f_k = output[0, k] - output[0, init_pred.item()]\n",
    "                pert_k = abs(f_k) / torch.norm(w_k.flatten(), p=2)\n",
    "                if pert_k < min_perturbation:\n",
    "                    min_perturbation = pert_k\n",
    "                    r_i = pert_k * w_k / torch.norm(w_k, p=2)\n",
    "\n",
    "        # Add perturbation to the image\n",
    "        r_tot += r_i\n",
    "        perturbed_image = image + (1 + epsilon) * r_tot\n",
    "        perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
    "\n",
    "        # Detach perturbed_image to prevent further gradient tracking\n",
    "        perturbed_image = perturbed_image.detach().requires_grad_(True)\n",
    "\n",
    "    return perturbed_image\n",
    "\n",
    "# Example usage\n",
    "# Assuming `model` is your trained CNN model\n",
    "model.eval()  # Set model to evaluation mode\n",
    "\n",
    "# Select a test image and its label\n",
    "test_image, test_label = next(iter(test_loader))\n",
    "\n",
    "# Perform DeepFool attack\n",
    "perturbed_image = deepfool_attack(test_image, model)\n",
    "\n",
    "# Display original and perturbed images\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(test_image.squeeze().numpy(), cmap='gray')\n",
    "plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(perturbed_image.squeeze().detach().numpy(), cmap='gray')\n",
    "plt.title('Perturbed Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac373a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on original test images: 97.90%\n",
      "Accuracy on perturbed test images: 100.00%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "def calculate_accuracy(model, dataloader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = (correct / total) * 100\n",
    "    return accuracy\n",
    "\n",
    "# Example usage\n",
    "model.eval()  # Set model to evaluation mode\n",
    "\n",
    "# Calculate accuracy on original test images\n",
    "accuracy_original = calculate_accuracy(model, test_loader)\n",
    "print(f'Accuracy on original test images: {accuracy_original:.2f}%')\n",
    "\n",
    "# Apply DeepFool attack on a batch of test images\n",
    "test_images, test_labels = next(iter(test_loader))\n",
    "perturbed_images = deepfool_attack(test_images, model)\n",
    "\n",
    "# Calculate accuracy on perturbed test images\n",
    "accuracy_perturbed = calculate_accuracy(model, [(perturbed_images, test_labels)])\n",
    "print(f'Accuracy on perturbed test images: {accuracy_perturbed:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f20f5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the model (example CNN architecture)\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, 1)\n",
    "        self.fc1 = nn.Linear(32 * 5 * 5, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.conv2(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = nn.MaxPool2d(2)(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Function to perform DeepFool attack\n",
    "def deepfool_attack(image, model, num_classes=10, max_iter=100, epsilon=1e-3):\n",
    "    image = image.clone().detach().requires_grad_(True)\n",
    "    perturbed_image = image.clone()\n",
    "\n",
    "    # Forward pass to get the initial prediction\n",
    "    output = model(perturbed_image)\n",
    "    _, init_pred = torch.max(output, 1)\n",
    "    perturbed_image.requires_grad_(True)  # Ensure requires_grad is set to True\n",
    "\n",
    "    # Initialize perturbation and iteration counter\n",
    "    r_tot = torch.zeros_like(image)\n",
    "\n",
    "    for iter_count in range(max_iter):\n",
    "        # Calculate gradients\n",
    "        output = model(perturbed_image)\n",
    "        _, pred_label = torch.max(output, 1)\n",
    "        grad_orig = torch.autograd.grad(output[0, init_pred.item()], perturbed_image, create_graph=True)[0]\n",
    "\n",
    "        # Check if the prediction is different from initial prediction\n",
    "        if pred_label != init_pred.item():\n",
    "            break\n",
    "\n",
    "        # Calculate perturbation\n",
    "        min_perturbation = np.inf\n",
    "        for k in range(num_classes):\n",
    "            if k != init_pred.item():\n",
    "                grad_curr = torch.autograd.grad(output[0, k], perturbed_image, create_graph=True)[0]\n",
    "                w_k = grad_curr - grad_orig\n",
    "                f_k = output[0, k] - output[0, init_pred.item()]\n",
    "                pert_k = abs(f_k) / torch.norm(w_k.flatten(), p=2)\n",
    "                if pert_k < min_perturbation:\n",
    "                    min_perturbation = pert_k\n",
    "                    r_i = pert_k * w_k / torch.norm(w_k, p=2)\n",
    "\n",
    "        # Add perturbation to the image\n",
    "        r_tot += r_i\n",
    "        perturbed_image = image + (1 + epsilon) * r_tot\n",
    "        perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
    "\n",
    "        # Detach perturbed_image to prevent further gradient tracking\n",
    "        perturbed_image = perturbed_image.detach().requires_grad_(True)\n",
    "\n",
    "    return perturbed_image\n",
    "    \n",
    "\n",
    "# Function to perform adversarial training\n",
    "def adversarial_training(model, train_loader, test_loader, num_epochs=10, eps=1e-3):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for images, labels in train_loader:\n",
    "            # Generate adversarial examples using DeepFool attack\n",
    "            adversarial_images = deepfool_attack(images, model)\n",
    "\n",
    "            # Compute predictions and loss for both original and adversarial examples\n",
    "            outputs_orig = model(images)\n",
    "            loss_orig = criterion(outputs_orig, labels)\n",
    "            outputs_adv = model(adversarial_images)\n",
    "            loss_adv = criterion(outputs_adv, labels)\n",
    "\n",
    "            # Total loss combines loss from original and adversarial examples\n",
    "            total_loss = loss_orig + loss_adv\n",
    "\n",
    "            # Backward propagation and optimization\n",
    "            optimizer.zero_grad()\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Evaluate model accuracy on test set\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        accuracy = (correct / total) * 100\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Test Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "\n",
    "\n",
    "    # Initialize the model\n",
    "    model = CNN()\n",
    "\n",
    "    # Perform adversarial training\n",
    "    adversarial_training(model, train_loader, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add51c1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
